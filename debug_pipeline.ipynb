{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Pipeline: FlowFigTabMiner\n",
    "\n",
    "Use this notebook to step-by-step debug the pipeline. You can override API keys and Model selection here directly without changing environment files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd6fdec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaowenyuan/Projects/FlowFigTabMiner/flowfigtabminer/lib/python3.9/site-packages/google/api_core/_python_version_support.py:246: FutureWarning: You are using a non-supported Python version (3.9.6). Google will not post any further updates to google.api_core supporting this Python version. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/zhaowenyuan/Projects/FlowFigTabMiner/flowfigtabminer/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/zhaowenyuan/Projects/FlowFigTabMiner/flowfigtabminer/lib/python3.9/site-packages/google/auth/__init__.py:54: FutureWarning: \n",
      "    You are using a Python version 3.9 past its end of life. Google will update\n",
      "    google-auth with critical bug fixes on a best-effort basis, but not\n",
      "    with any other fixes or features. Please upgrade your Python version,\n",
      "    and then update google-auth.\n",
      "    \n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n",
      "/Users/zhaowenyuan/Projects/FlowFigTabMiner/flowfigtabminer/lib/python3.9/site-packages/google/oauth2/__init__.py:40: FutureWarning: \n",
      "    You are using a Python version 3.9 past its end of life. Google will update\n",
      "    google-auth with critical bug fixes on a best-effort basis, but not\n",
      "    with any other fixes or features. Please upgrade your Python version,\n",
      "    and then update google-auth.\n",
      "    \n",
      "  warnings.warn(eol_message.format(\"3.9\"), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Provider: qwen\n",
      "Current Model: qwen-vl-max\n",
      "Testing LLM connection...\n",
      "LLM Factory initialized (Uncomment lines above to test actual call)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaowenyuan/Projects/FlowFigTabMiner/flowfigtabminer/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/zhaowenyuan/Projects/FlowFigTabMiner/src/llm_factory.py:1: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup & Configuration\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Ensure project root is in path\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from config import Config\n",
    "from src.llm_factory import LLMFactory\n",
    "\n",
    "# Note: All configuration is now centrally managed by src.config.Config and .env\n",
    "# This ensures consistency between this notebook and main.py\n",
    "\n",
    "print(f\"Current Provider: {Config.LLM_PROVIDER}\")\n",
    "print(f\"Current Model: {Config.LLM_MODEL_NAME}\")\n",
    "\n",
    "# Test LLM Connection\n",
    "try:\n",
    "    print(\"Testing LLM connection...\")\n",
    "    # response = LLMFactory.create_completion(\"Hello, config is working!\")\n",
    "    # print(f\"LLM Response: {response}\")\n",
    "    print(\"LLM Factory initialized (Uncomment lines above to test actual call)\")\n",
    "except Exception as e:\n",
    "    print(f\"LLM Connection Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05ffd3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Docling...\n"
     ]
    }
   ],
   "source": [
    "# 2. PDF Parsing (Step 1)\n",
    "from src.parsing.docling_wrapper import parse_pdf_to_markdown\n",
    "\n",
    "input_pdf = \"data/input/example.pdf\"\n",
    "if not os.path.exists(input_pdf):\n",
    "    print(f\"Warning: {input_pdf} not found. Please place a PDF there.\")\n",
    "else:\n",
    "    print(\"Running Docling...\")\n",
    "    # markdown_text = parse_pdf_to_markdown(input_pdf)\n",
    "    # print(f\"Docling extracted {len(markdown_text)} characters\")\n",
    "    # print(markdown_text[:500] + \"...\") # Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973f100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing TF-ID Detector (this will download models to local dir)...\n",
      "Loading TF-ID (Florence-2) model: yifeihu/TF-ID-base on mps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaowenyuan/Projects/FlowFigTabMiner/flowfigtabminer/lib/python3.9/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly defined. However, it doesn't directly inherit from `GenerationMixin`. From \ud83d\udc49v4.50\ud83d\udc48 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATCHING: Adding GenerationMixin to Florence2LanguageForConditionalGeneration bases for compatibility.\n",
      "PATCHING: Initializing missing generation_config for language_model.\n",
      "{\n",
      "  \"page_1\": [\n",
      "    {\n",
      "      \"label\": \"table\",\n",
      "      \"score\": 1.0,\n",
      "      \"box\": [\n",
      "        95.88,\n",
      "        59.33,\n",
      "        1093.93,\n",
      "        193.79\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"page_2\": [\n",
      "    {\n",
      "      \"label\": \"figure\",\n",
      "      \"score\": 1.0,\n",
      "      \"box\": [\n",
      "        360.28,\n",
      "        948.41,\n",
      "        1095.12,\n",
      "        1438.83\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"page_3\": [\n",
      "    {\n",
      "      \"label\": \"figure\",\n",
      "      \"score\": 1.0,\n",
      "      \"box\": [\n",
      "        361.47,\n",
      "        556.07,\n",
      "        1096.32,\n",
      "        1437.25\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"page_4\": [\n",
      "    {\n",
      "      \"label\": \"table\",\n",
      "      \"score\": 1.0,\n",
      "      \"box\": [\n",
      "        603.24,\n",
      "        847.16,\n",
      "        1095.12,\n",
      "        1441.99\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"page_5\": [\n",
      "    {\n",
      "      \"label\": \"figure\",\n",
      "      \"score\": 1.0,\n",
      "      \"box\": [\n",
      "        605.62,\n",
      "        611.44,\n",
      "        1095.12,\n",
      "        1109.77\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"figure\",\n",
      "      \"score\": 1.0,\n",
      "      \"box\": [\n",
      "        605.62,\n",
      "        111.53,\n",
      "        1095.12,\n",
      "        579.8\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"page_6\": [\n",
      "    {\n",
      "      \"label\": \"figure\",\n",
      "      \"score\": 1.0,\n",
      "      \"box\": [\n",
      "        95.88,\n",
      "        959.48,\n",
      "        584.19,\n",
      "        1441.99\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"figure\",\n",
      "      \"score\": 1.0,\n",
      "      \"box\": [\n",
      "        606.81,\n",
      "        972.14,\n",
      "        1095.12,\n",
      "        1440.41\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"page_7\": [\n",
      "    {\n",
      "      \"label\": \"table\",\n",
      "      \"score\": 1.0,\n",
      "      \"box\": [\n",
      "        95.88,\n",
      "        657.32,\n",
      "        584.19,\n",
      "        883.55\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"label\": \"figure\",\n",
      "      \"score\": 1.0,\n",
      "      \"box\": [\n",
      "        94.68,\n",
      "        106.79,\n",
      "        584.19,\n",
      "        616.19\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"page_8\": [\n",
      "    {\n",
      "      \"label\": \"table\",\n",
      "      \"score\": 1.0,\n",
      "      \"box\": [\n",
      "        94.68,\n",
      "        60.91,\n",
      "        1095.12,\n",
      "        698.45\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Saving detected crops to data/intermediate...\n",
      "Saved 11 images: ['data/intermediate/example/tables/page_1_table_0.png', 'data/intermediate/example/figures/page_2_figure_0.png', 'data/intermediate/example/figures/page_3_figure_0.png', 'data/intermediate/example/tables/page_4_table_0.png', 'data/intermediate/example/figures/page_5_figure_0.png', 'data/intermediate/example/figures/page_5_figure_1.png', 'data/intermediate/example/figures/page_6_figure_0.png', 'data/intermediate/example/figures/page_6_figure_1.png', 'data/intermediate/example/tables/page_7_table_0.png', 'data/intermediate/example/figures/page_7_figure_1.png', 'data/intermediate/example/tables/page_8_table_0.png']\n"
     ]
    }
   ],
   "source": [
    "# 3. TF-ID Extraction (Step 2 - Track B)\n",
    "import src.parsing.active_area_detector\n",
    "from importlib import reload\n",
    "reload(src.parsing.active_area_detector)\n",
    "from src.parsing.active_area_detector import ActiveAreaDetector\n",
    "\n",
    "if os.path.exists(input_pdf):\n",
    "    print(\"Initializing TF-ID Detector (this will download models to local dir)...\")\n",
    "    detector = ActiveAreaDetector()\n",
    "    detections = detector.process_pdf(input_pdf)\n",
    "    import json\n",
    "    print(json.dumps(detections, indent=2))\n",
    "    \n",
    "    # --- SAVE CROPS ---\n",
    "    print(\"Saving detected crops to data/intermediate...\")\n",
    "    saved_paths = detector.save_crops(input_pdf, detections, \"data/intermediate\")\n",
    "    print(f\"Saved {len(saved_paths)} images: {saved_paths}\")\n",
    "    \n",
    "    # Define variables for next steps\n",
    "    table_images = [p for p in saved_paths if '_table_' in p]\n",
    "    figure_images = [p for p in saved_paths if '_figure_' in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "261af1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Table Extraction (Step 3A)\n",
    "from src.extraction.table_agent import extract_table\n",
    "import os\n",
    "\n",
    "extracted_tables = []\n",
    "# Use the cropped images from Step 3\n",
    "if 'table_images' in locals() and table_images:\n",
    "    print(f\"Processing {len(table_images)} Tables...\")\n",
    "    for img_path in table_images:\n",
    "        print(f\"--> Extracting: {os.path.basename(img_path)}\")\n",
    "        try:\n",
    "            result = extract_table(img_path)\n",
    "            if result.get(\"is_valid\"):\n",
    "                print(\"    \u2705 Valid Table Extracted\")\n",
    "                extracted_tables.append({\"source\": img_path, \"data\": result})\n",
    "            else:\n",
    "                print(f\"    \u274c Rejected: {result.get('reason')}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    \u26a0\ufe0f Error: {e}\")\n",
    "else:\n",
    "    print(\"No table images found from Step 3.\")\n",
    "\n",
    "print(f\"\\nTotal Valid Tables: {len(extracted_tables)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e332c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Figure Extraction (Step 3B)\n",
    "from src.extraction.figure_agent import extract_figure\n",
    "import os\n",
    "\n",
    "extracted_figures = []\n",
    "if 'figure_images' in locals() and figure_images:\n",
    "    print(f\"Processing {len(figure_images)} Figures...\")\n",
    "    for img_path in figure_images:\n",
    "        print(f\"--> Extracting: {os.path.basename(img_path)}\")\n",
    "        try:\n",
    "            result = extract_figure(img_path)\n",
    "            if result.get(\"is_valid\"):\n",
    "                print(\"    \u2705 Valid Figure Extracted\")\n",
    "                extracted_figures.append({\"source\": img_path, \"data\": result})\n",
    "            else:\n",
    "                print(f\"    \u274c Rejected: {result.get('reason')}\")\n",
    "        except Exception as e:\n",
    "            print(f\"    \u26a0\ufe0f Error: {e}\")\n",
    "else:\n",
    "    print(\"No figure images found from Step 3.\")\n",
    "\n",
    "print(f\"\\nTotal Valid Figures: {len(extracted_figures)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "221d1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Fusion (Step 4)\n",
    "# from src.fusion.data_merger import fuse_data\n",
    "\n",
    "# final_dataset = fuse_data(table_data, figure_data, global_context)\n",
    "# print(\"Fusion Complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flowfigtabminer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}